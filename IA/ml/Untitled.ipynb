{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Untitled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9tAOTpTyLOg",
        "outputId": "cf84e0dc-0023-4a06-eddc-252914002cc1"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"data\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['heart.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-_--OLLyLOt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data splitting/parameter tuning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# ML models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Feature processing\n",
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmUqLIVTyLOx"
      },
      "source": [
        "heart_path = \"data/heart.csv\"\n",
        "heart_data = pd.read_csv(heart_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtGdMGyuyLO1",
        "outputId": "36aa2296-957e-476d-c726-6abe592414ab"
      },
      "source": [
        "heart_data = pd.get_dummies(heart_data)\n",
        "heart_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6BPPXwyyLO4"
      },
      "source": [
        "# Getting features and target\n",
        "X = heart_data.drop([\"target\"], axis=1)\n",
        "y = heart_data[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNGtJI4SyLO5",
        "outputId": "a6c7c58f-e460-448a-a075-ece371547cdf"
      },
      "source": [
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_predictions = cross_val_predict(rf_model, X, y, cv=5)\n",
        "print(confusion_matrix(y, rf_predictions))\n",
        "rf_scores = cross_val_score(rf_model, X, y, scoring=\"recall\", cv=5)\n",
        "print(\"recall:\", rf_scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[110  28]\n",
            " [ 26 139]]\n",
            "recall: 0.8484848484848484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XchFO5JDyLO7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tOCmkzsyLO8"
      },
      "source": [
        "Focus on SVMÂ¶\n",
        "Besides that, SVM is showing the most interesting results. Due to the fact that is already doing a great job on false negatives (but having a hard time knowing when someone is not sick). However I think it is a good idea to choose SVM as main model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX3LnirTyLO_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eeH5i_kyLPB"
      },
      "source": [
        "Feature scaling\n",
        "We are going to go further using SVM, so lets apply feature scaling to our data. That should make our SVM model better. The type of scaling we will apply is called MinMaxScaler in sklearn.\n",
        "\n",
        "It is important to remember the fact that this is a really good practice to do if we want"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUcF0h4_yLPD"
      },
      "source": [
        "X[\"age\"] = X[\"age\"].map(lambda x: (x - X[\"age\"].min()) / (X[\"age\"].max() - X[\"age\"].min()))\n",
        "X[\"trestbps\"] = X[\"trestbps\"].map(lambda x: (x - X[\"trestbps\"].min()) / (X[\"trestbps\"].max() - X[\"trestbps\"].min()))\n",
        "X[\"chol\"] = X[\"chol\"].map(lambda x: (x - X[\"chol\"].min()) / (X[\"chol\"].max() - X[\"chol\"].min()))\n",
        "X[\"thalach\"] = X[\"thalach\"].map(lambda x: (x - X[\"thalach\"].min()) / (X[\"thalach\"].max() - X[\"thalach\"].min()))\n",
        "X[\"oldpeak\"] = X[\"oldpeak\"].map(lambda x: (x - X[\"oldpeak\"].min()) / (X[\"oldpeak\"].max() - X[\"oldpeak\"].min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcj4RTLHyLPE",
        "outputId": "929b957b-8be3-4ab8-b19d-90514248fac8"
      },
      "source": [
        "# Support Vector Machine\n",
        "svc_model = SVC(gamma=\"auto\")\n",
        "svc_predictions = cross_val_predict(svc_model, X, y, cv=5)\n",
        "print(confusion_matrix(y, svc_predictions))\n",
        "svc_scores = cross_val_score(svc_model, X, y, scoring=\"recall\", cv=5)\n",
        "print(\"recall:\", svc_scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 99  39]\n",
            " [ 10 155]]\n",
            "recall: 0.9393939393939394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO0QVgtByQfr"
      },
      "source": [
        "TESTING NEW ML ALGO\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asJUgsB5yLPH"
      },
      "source": [
        "# MLP\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow import lite\n",
        "import time\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 25\n",
        "learning_rate = 0.0001\n",
        "\n",
        "mlp_model = Sequential()\n",
        "\n",
        "#First Hidden Layer\n",
        "mlp_model.add(Dense(512, activation='relu', name='hidden_layer_1', input_dim = X.shape[1]))\n",
        "\n",
        "#Second  Hidden Layer\n",
        "mlp_model.add(Dense(512, activation='relu', name='hidden_layer_2'))\n",
        "\n",
        "#Output Layer\n",
        "output = mlp_model.add(Dense(1, activation='sigmoid', name='predictions_output'))\n",
        "\n",
        "mlp_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoG-JNYMyLPJ"
      },
      "source": [
        "# Specify the training configuration (optimizer, loss, metrics)\n",
        "start_time = time.time()\n",
        "\n",
        "mlp_model.compile(optimizer='adam',  # Optimizer\n",
        "              # Loss function to minimize\n",
        "              loss='binary_crossentropy',\n",
        "              # List of metrics to monitor\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = mlp_model.fit(X, y, batch_size, epochs)\n",
        "\n",
        "# The returned \"history\" object holds a record\n",
        "# of the loss and metric values during training\n",
        "#print('\\nhistory dict:', history.history)\n",
        "\n",
        "print(\"> Execution time: %s secondes ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00yuwOE4yLPJ"
      },
      "source": [
        "# Convert the model in tflite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(mlp_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save le model\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHJ-4pqqy4H0"
      },
      "source": [
        "\n",
        "#Verify model imput and output details\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Print input shape and type\n",
        "inputs = interpreter.get_input_details()\n",
        "print('{} input(s):'.format(len(inputs)))\n",
        "for i in range(0, len(inputs)):\n",
        "    print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))\n",
        "\n",
        "# Print output shape and type\n",
        "outputs = interpreter.get_output_details()\n",
        "print('\\n{} output(s):'.format(len(outputs)))\n",
        "for i in range(0, len(outputs)):\n",
        "    print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGSQ55S2y-k5"
      },
      "source": [
        "#Inference data\n",
        "existing_data = [[63, 45, 233, 150, 2.3, 0, 0,\t1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]]\n",
        "new_data = [[63, 45, 233, 150, 2.3, 0, 0,\t1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1]]\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}